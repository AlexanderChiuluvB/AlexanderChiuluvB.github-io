<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="人脸识别one shot learning 因为公司的数据库里面很可能只有该名员工一张照片，因此用一张图片投入神经网络，通过softmax输出分类显然不可行。因此应该学习一个相似函数，如果函数的结果大于某个阈值，说明不匹配，否则说明匹配。 siamese network x1投入网络中，得到全连接层一个output vector，这个vector维度是128x1,记为encoding of x1">
<meta property="og:type" content="article">
<meta property="og:title" content="DL-C4W4">
<meta property="og:url" content="http://AlexanderChiuluvB.github.io/2019/01/01/DL-C4W4/index.html">
<meta property="og:site_name" content="Alex Chiu">
<meta property="og:description" content="人脸识别one shot learning 因为公司的数据库里面很可能只有该名员工一张照片，因此用一张图片投入神经网络，通过softmax输出分类显然不可行。因此应该学习一个相似函数，如果函数的结果大于某个阈值，说明不匹配，否则说明匹配。 siamese network x1投入网络中，得到全连接层一个output vector，这个vector维度是128x1,记为encoding of x1">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-159.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-160.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-161.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/something.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/waisting.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/learning.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/hundred.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/预处理.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-162.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/梗概.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-163.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/style.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/feifeili.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-164.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-165.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/howcan.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/thisss.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-166.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/af.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-167.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/J_style.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/cosst.png">
<meta property="og:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-168.png">
<meta property="og:updated_time" content="2019-01-01T15:06:02.139Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="DL-C4W4">
<meta name="twitter:description" content="人脸识别one shot learning 因为公司的数据库里面很可能只有该名员工一张照片，因此用一张图片投入神经网络，通过softmax输出分类显然不可行。因此应该学习一个相似函数，如果函数的结果大于某个阈值，说明不匹配，否则说明匹配。 siamese network x1投入网络中，得到全连接层一个output vector，这个vector维度是128x1,记为encoding of x1">
<meta name="twitter:image" content="http://alexanderchiuluvb.github.io/home/alex/图片/2018-159.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://AlexanderChiuluvB.github.io/2019/01/01/DL-C4W4/"/>





  <title>DL-C4W4 | Alex Chiu</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Alex Chiu</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-schedule">
          <a href="/schedule/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-calendar"></i> <br />
            
            Schedule
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            Sitemap
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://AlexanderChiuluvB.github.io/2019/01/01/DL-C4W4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Alex Chiu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/header.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Alex Chiu">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">DL-C4W4</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-01T15:58:22+08:00">
                2019-01-01
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h3 id="人脸识别"><a href="#人脸识别" class="headerlink" title="人脸识别"></a>人脸识别</h3><h4 id="one-shot-learning"><a href="#one-shot-learning" class="headerlink" title="one shot learning"></a>one shot learning</h4><p><img src="/home/alex/图片/2018-159.png" alt="filename dy exists, renamed"></p>
<p>因为公司的数据库里面很可能只有该名员工一张照片，因此用一张图片投入神经网络，通过softmax输出分类显然不可行。因此应该学习一个相似函数，如果函数的结果大于某个阈值，说明不匹配，否则说明匹配。</p>
<h4 id="siamese-network"><a href="#siamese-network" class="headerlink" title="siamese network"></a>siamese network</h4><p><img src="/home/alex/图片/2018-160.png" alt="filename already enamed"></p>
<p>x1投入网络中，得到全连接层一个output vector，这个vector维度是128x1,记为encoding of x1</p>
<p>另外一张图片x2喂入网络，得到另外一个vector叫做encoding of x2</p>
<p>然后把二者距离定义为二者编码之差的范数。</p>
<p>更准确地说,神经网络的参数定义了一个编码函数f(x (i) ),如果给定输入图像x(i),这个网络会输出x (i) 的 128 维的编码。</p>
<h4 id="三元组损失"><a href="#三元组损失" class="headerlink" title="三元组损失"></a>三元组损失</h4><p><img src="/home/alex/图片/2018-161.png" alt="filenamalready exists, renamed"></p>
<p>目标：</p>
<p><img src="/home/alex/图片/something.png" alt="upload succesul"></p>
<p>遇到的问题：</p>
<p>如果f总是输出0，上面式子无意义</p>
<p>为了阻止网络出现这种情况,我们需要修改这个目标,也就是,这个不能是刚好小于等<br>于 0,应该是比 0 还要小,所以这个应该小于一个−a值(即||f(A) − f(P)|| 2 − ||f(A) −<br>f(N)|| 2 ≤ −a),这里的a是另一个超参数,这个就可以阻止网络输出无用的结果。按照惯<br>例,我们习惯写+a(即||f(A) − f(P)|| 2 − ||f(A) − f(N)|| 2 + a ≤ 0),而不是把−a写在后<br>面,它也叫做间隔(margin)</p>
<p>总结：</p>
<p>三元组损失函数的定义基于三张图片,假如三张图片A、 P、 N,即 anchor 样本、 positive<br>样本和 negative 样本,其中 positive 图片和 anchor 图片是同一个人,但是 negative 图片和<br>anchor 不是同一个人。</p>
<h4 id="定义损失函数"><a href="#定义损失函数" class="headerlink" title="定义损失函数"></a>定义损失函数</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">L(A, P, N) = max(||f(A) − f(P)|| 2 − ||f(A) − f(N)|| 2 + a, 0)</span><br></pre></td></tr></table></figure>
<p>这是一个三元组定义的损失,整个网络的代价函数应该是训练集中这些单个三元组损失的总和。</p>
<h4 id="挑选数据集"><a href="#挑选数据集" class="headerlink" title="挑选数据集"></a>挑选数据集</h4><p>现在我们来看,你如何选择这些三元组来形成训练集。一个问题是如果你从训练集中,<br>随机地选择A、 P和N,遵守A和P是同一个人,而A和N是不同的人这一原则。有个问题就是,<br>如果随机的选择它们,那么这个约束条件(d(A, P) + a ≤ d(A, N))很容易达到,因为随机<br>选择的图片,A和N比A和P差别很大的概率很大。我希望你还记得这个符号d(A, P)就是前几<br>个幻灯片里写的||f(A) − f(P)|| 2 ,d(A, N)就是||f(A) − f(N)|| 2 ,d(A, P) + a ≤ d(A, N)即<br>||f(A) − f(P)|| 2 + a ≤ ||f(A) − f(N)|| 2 。但是如果A和N是随机选择的不同的人,有很大的<br>可能性||f(A) − f(N)|| 2 会比左边这项||f(A) − f(P)|| 2 大,而且差距远大于a,这样网络并不<br>能从中学到什么。</p>
<p>因此要挑选最难学习的，就是要挑选 d(A,P)约等于 d(A,N)的三元组，<br>只有这样梯度下降法才有用，才能学到有意义的参数。</p>
<h4 id="summary"><a href="#summary" class="headerlink" title="summary"></a>summary</h4><p><img src="/home/alex/图片/waisting.png" alt="upload succesl"></p>
<h3 id="人脸验证与二分类"><a href="#人脸验证与二分类" class="headerlink" title="人脸验证与二分类"></a>人脸验证与二分类</h3><p><img src="/home/alex/图片/learning.png" alt="upload ul"></p>
<p><img src="/home/alex/图片/hundred.png" alt="uploadccessful"></p>
<h4 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h4><p><img src="/home/alex/图片/预处理.png" alt="upload successful"></p>
<p>如果这是一张新图片(编号 1),<br>当员工走进门时,希望门可以自动为他们打开,这个(编号 2)是在数据库中的图片,不需<br>要每次都计算这些特征(编号 6),不需要每次都计算这个嵌入,你可以提前计算好,那么<br>当一个新员工走近时,你可以使用上方的卷积网络来计算这些编码(编号 5),然后使用它,<br>^ 。<br>和预先计算好的编码进行比较,然后输出预测值</p>
<h3 id="神经风格迁移"><a href="#神经风格迁移" class="headerlink" title="神经风格迁移"></a>神经风格迁移</h3><p><img src="/home/alex/图片/2018-162.png" alt="filename aeady exists, renamed"></p>
<p>怎么判断生成图像的好坏呢?我们把这个代价函数定义为两个部分。<br>J content (C, G)<br>第一部分被称作内容代价,这是一个关于内容图片和生成图片的函数,它是用来度量生<br>成图片G的内容与内容图片C的内容有多相似。<br>J style (S, G)<br>然后我们会把结果加上一个风格代价函数,也就是关于S和G的函数,用来度量图片G的<br>风格和图片S的风格的相似度。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">J(G) = aJ content (C, G) + βJ style (S, G）</span><br></pre></td></tr></table></figure></p>
<h4 id="梗概"><a href="#梗概" class="headerlink" title="梗概"></a>梗概</h4><p><img src="/home/alex/图片/梗概.png" alt="uplosuccessful"></p>
<h4 id="content-cost-function"><a href="#content-cost-function" class="headerlink" title="content cost function"></a>content cost function</h4><p><img src="/home/alex/图片/2018-163.png" alt="filename eady exiss, renamed"></p>
<p>现在你需要衡量假如有一个内容图片和一个生成图片他们在内容上的相似度,我们令这<br>个a [l][C] 和a [l][G] ,代表这两个图片C和G的l层的激活函数值。如果这两个激活值相似,那么<br>就意味着两个图片的内容相似。<br>1<br>我们定义这个: J content (C, G) = 2 ||a [l][C] − a [l][G] || 2 ,为两个激活值不同或者相似的程度,<br>我们取l层的隐含单元的激活值,按元素相减,内容图片的激活值与生成图片相比较,然后<br>510第四门课 卷积神经网络(Convolutional Neural Networks)-第四周 特殊应用:人脸识别和神经风格转换<br>(Special applications: Face recognition &amp;Neural style transfer)<br>1<br>取平方,也可以在前面加上归一化或者不加,比如 或者其他的,都影响不大,因为这都可以<br>2<br>由这个超参数 α 来调整(J(G) = aJ content (C, G) + βJ style (S, G))。</p>
<h3 id="style-cost-function"><a href="#style-cost-function" class="headerlink" title="style cost function"></a>style cost function</h3><p><img src="/home/alex/图片/style.png" alt="upload successf"></p>
<p><img src="/home/alex/图片/feifeili.png" alt="upload success"></p>
<p><img src="/home/alex/图片/2018-164.png" alt="filenlready exists, renamed"></p>
<p>对于这个风格矩阵,你要做的就是计算这个矩阵也就是G [l] 矩阵,它是个n c × n c 的矩阵,<br>也就是一个方阵。记住,因为这里有n c 个通道,所以矩阵的大小是n c × n c 。以便计算每一对<br>[l]<br>激活项的相关系数,所以G kk ′ 可以用来测量k通道与k′通道中的激活项之间的相关系数,k和<br>k′会在 1 到n c 之间取值,n c 就是l层中通道的总数量。</p>
<p>可以看做这是两个通道间的协方差。</p>
<h3 id="implementation"><a href="#implementation" class="headerlink" title="implementation"></a>implementation</h3><h4 id="using-an-ConvNet-to-compute-encodings"><a href="#using-an-ConvNet-to-compute-encodings" class="headerlink" title="using an ConvNet to compute encodings"></a>using an ConvNet to compute encodings</h4><p><img src="/home/alex/图片/2018-165.png" alt="filename already ets, renamed"></p>
<p>这里使用的是Inception Network</p>
<p>把两张图片分别转换成2个128维的向量，然后计算这两个向量的距离。</p>
<p><img src="/home/alex/图片/howcan.png" alt="upload cessful"></p>
<h4 id="compute-triplet-loss"><a href="#compute-triplet-loss" class="headerlink" title="compute triplet loss"></a>compute triplet loss</h4><p><img src="/home/alex/图片/thisss.png" alt="uploadcessful"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># GRADED FUNCTION: triplet_loss</span><br><span class="line"></span><br><span class="line">def triplet_loss(y_true, y_pred, alpha = 0.2):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Implementation of the triplet loss as defined by formula (3)</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    y_true -- true labels, required when you define a loss in Keras, you don&apos;t need it in this function.</span><br><span class="line">    y_pred -- python list containing three objects:</span><br><span class="line">            anchor -- the encodings for the anchor images, of shape (None, 128)</span><br><span class="line">            positive -- the encodings for the positive images, of shape (None, 128)</span><br><span class="line">            negative -- the encodings for the negative images, of shape (None, 128)</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    loss -- real number, value of the loss</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]</span><br><span class="line">    </span><br><span class="line">    ### START CODE HERE ### (≈ 4 lines)</span><br><span class="line">    # Step 1: Compute the (encoding) distance between the anchor and the positive, you will need to sum over axis=-1</span><br><span class="line">    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)</span><br><span class="line">    # Step 2: Compute the (encoding) distance between the anchor and the negative, you will need to sum over axis=-1</span><br><span class="line">    neg_dist =  tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)</span><br><span class="line">    # Step 3: subtract the two previous distances and add alpha.</span><br><span class="line">    basic_loss = tf.add(alpha,tf.subtract(pos_dist,neg_dist))</span><br><span class="line">    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.</span><br><span class="line">    loss = tf.reduce_sum(tf.maximum(basic_loss,0))</span><br><span class="line">    ### END CODE HERE ###</span><br><span class="line">    </span><br><span class="line">    return loss</span><br></pre></td></tr></table></figure>
<h4 id="verify"><a href="#verify" class="headerlink" title="verify"></a>verify</h4><p>这里设定阈值！与数据库中已有的照片进行比较</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"># GRADED FUNCTION: verify</span><br><span class="line"></span><br><span class="line">def verify(image_path, identity, database, model):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Function that verifies if the person on the &quot;image_path&quot; image is &quot;identity&quot;.</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    image_path -- path to an image</span><br><span class="line">    identity -- string, name of the person you&apos;d like to verify the identity. Has to be a resident of the Happy house.</span><br><span class="line">    database -- python dictionary mapping names of allowed people&apos;s names (strings) to their encodings (vectors).</span><br><span class="line">    model -- your Inception model instance in Keras</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    dist -- distance between the image_path and the image of &quot;identity&quot; in the database.</span><br><span class="line">    door_open -- True, if the door should open. False otherwise.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    ### START CODE HERE ###</span><br><span class="line">    </span><br><span class="line">    # Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line)</span><br><span class="line">    encoding = img_to_encoding(image_path,model)</span><br><span class="line">    </span><br><span class="line">    # Step 2: Compute distance with identity&apos;s image (≈ 1 line)</span><br><span class="line">    dist = np.linalg.norm(database[identity]-encoding)</span><br><span class="line">    </span><br><span class="line">    # Step 3: Open the door if dist &lt; 0.7, else don&apos;t open (≈ 3 lines)</span><br><span class="line">    if dist&lt;0.7:</span><br><span class="line">        print(&quot;It&apos;s &quot; + str(identity) + &quot;, welcome home!&quot;)</span><br><span class="line">        door_open = True</span><br><span class="line">    else:</span><br><span class="line">        print(&quot;It&apos;s not &quot; + str(identity) + &quot;, please go away&quot;)</span><br><span class="line">        door_open = False</span><br><span class="line">        </span><br><span class="line">    ### END CODE HERE ###</span><br><span class="line">        </span><br><span class="line">    return dist, door_open</span><br></pre></td></tr></table></figure>
<h3 id="face-recognition"><a href="#face-recognition" class="headerlink" title="face recognition"></a>face recognition</h3><p>在数据库中寻找dist与输入图片最小的，结果就是识别出来的人。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"> GRADED FUNCTION: who_is_it</span><br><span class="line"></span><br><span class="line">def who_is_it(image_path, database, model):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Implements face recognition for the happy house by finding who is the person on the image_path image.</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    image_path -- path to an image</span><br><span class="line">    database -- database containing image encodings along with the name of the person on the image</span><br><span class="line">    model -- your Inception model instance in Keras</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    min_dist -- the minimum distance between image_path encoding and the encodings from the database</span><br><span class="line">    identity -- string, the name prediction for the person on image_path</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    ### START CODE HERE ### </span><br><span class="line">    </span><br><span class="line">    ## Step 1: Compute the target &quot;encoding&quot; for the image. Use img_to_encoding() see example above. ## (≈ 1 line)</span><br><span class="line">    encoding = img_to_encoding(image_path,model)</span><br><span class="line">    </span><br><span class="line">    ## Step 2: Find the closest encoding ##</span><br><span class="line">    </span><br><span class="line">    # Initialize &quot;min_dist&quot; to a large value, say 100 (≈1 line)</span><br><span class="line">    min_dist = 100</span><br><span class="line">    </span><br><span class="line">    # Loop over the database dictionary&apos;s names and encodings.</span><br><span class="line">    for (name, db_enc) in database.items():</span><br><span class="line">        </span><br><span class="line">        # Compute L2 distance between the target &quot;encoding&quot; and the current &quot;emb&quot; from the database. (≈ 1 line)</span><br><span class="line">        dist = np.linalg.norm(db_enc-encoding)</span><br><span class="line"></span><br><span class="line">        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)</span><br><span class="line">        if dist&lt;min_dist:</span><br><span class="line">            min_dist = dist</span><br><span class="line">            identity = name</span><br><span class="line"></span><br><span class="line">    ### END CODE HERE ###</span><br><span class="line">    </span><br><span class="line">    if min_dist &gt; 0.7:</span><br><span class="line">        print(&quot;Not in the database.&quot;)</span><br><span class="line">    else:</span><br><span class="line">        print (&quot;it&apos;s &quot; + str(identity) + &quot;, the distance is &quot; + str(min_dist))</span><br><span class="line">        </span><br><span class="line">    return min_dist, identity</span><br></pre></td></tr></table></figure>
<h3 id="Neural-Style-Transfer"><a href="#Neural-Style-Transfer" class="headerlink" title="Neural Style Transfer"></a>Neural Style Transfer</h3><h4 id="compute-the-content-cost"><a href="#compute-the-content-cost" class="headerlink" title="compute the content cost"></a>compute the content cost</h4><p>在网络里面，浅层的卷积网络倾向于检测一些如边缘与简单内容的低层次特征，深层的卷积网络倾向于检测一些高层次特征例如目标的类别等。</p>
<p>我们目标是生成的图片G与输入图片C有相同的内容。假设选定了某层的激活层来代表图片的内容，在实践中，选择那些不太深也不太浅——即中间的网络。</p>
<p>所以假定你选择一个隐含层，设定图片C作为预训练的VGG网络的输入，然后前向反馈，记a^[c]为你选择的隐含层的激活。 这将是一个维度为nHxnWxnC的张量。<br>对输入的图片G重复上述操作。</p>
<p>我们定义损失函数如下</p>
<p><img src="/home/alex/图片/2018-166.png" alt="filena already exists, renamed"></p>
<p>这里的nH,nW,nC分别为你所选择的隐含层的高度，宽度与通道数目。</p>
<p>为了方便计算J_content(C,G) ，需要把三维的volumns unrolled成二维的矩阵。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># GRADED FUNCTION: compute_content_cost</span><br><span class="line"></span><br><span class="line">def compute_content_cost(a_C, a_G):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Computes the content cost</span><br><span class="line">    </span><br><span class="line">    Arguments:</span><br><span class="line">    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C </span><br><span class="line">    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G</span><br><span class="line">    </span><br><span class="line">    Returns: </span><br><span class="line">    J_content -- scalar that you compute using equation 1 above.</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    ### START CODE HERE ###</span><br><span class="line">    # Retrieve dimensions from a_G (≈1 line)</span><br><span class="line">    m, n_H, n_W, n_C = a_G.get_shape().as_list()</span><br><span class="line">    </span><br><span class="line">    new_shape = [m,(n_H*n_W),n_C]</span><br><span class="line">    </span><br><span class="line">    # Reshape a_C and a_G (≈2 lines)</span><br><span class="line">    a_C_unrolled = tf.reshape(a_C,shape=new_shape)</span><br><span class="line">    a_G_unrolled = tf.reshape(a_G,shape=new_shape)</span><br><span class="line">    </span><br><span class="line">    # compute the cost with tensorflow (≈1 line)</span><br><span class="line">    J_content = 1/(4*n_H*n_W*n_C)*tf.reduce_sum(tf.square(tf.subtract(a_C_unrolled,a_G_unrolled)))</span><br><span class="line">    ### END CODE HERE ###</span><br><span class="line">    </span><br><span class="line">    return J_content</span><br></pre></td></tr></table></figure>
<h4 id="STYLE-MATRIX"><a href="#STYLE-MATRIX" class="headerlink" title="STYLE MATRIX"></a>STYLE MATRIX</h4><p>在线性代数中，风格矩阵也叫作Gram矩阵.</p>
<p>matrix G of set of vectors(v1,v2…vn)</p>
<p>是任意两个向量vi,vj的点乘的矩阵，看作是来衡量vi<br>与vj是有多相似的。如果vi与vj很相似，得到的点乘也会越大。</p>
<p>Gij=vTivj=np.dot(vi,vj)Gij=viTvj=np.dot(vi,vj). In other words, GijGij compares how similar vivi is to vjvj: </p>
<p><img src="/home/alex/图片/af.png" alt="upload sucssful"></p>
<p>这个矩阵维度是(nc,nc),nc是filter的数量，Gij的值衡量了filter_i的激活与filter_j的激活的相似程度。</p>
<p>而矩阵的对角元素G_ii衡量了filter_i的活跃程度。举个例子，如果filter_i是用来检测竖直特征的，那么Gii就衡量了整张图片出现竖直特征的总体情况。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># GRADED FUNCTION: gram_matrix</span><br><span class="line"></span><br><span class="line">def gram_matrix(A):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Argument:</span><br><span class="line">    A -- matrix of shape (n_C, n_H*n_W)</span><br><span class="line">    </span><br><span class="line">    Returns:</span><br><span class="line">    GA -- Gram matrix of A, of shape (n_C, n_C)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    ### START CODE HERE ### (≈1 line)</span><br><span class="line">    GA =  tf.matmul(A,tf.transpose(A))</span><br><span class="line">    ### END CODE HERE ###</span><br><span class="line">    </span><br><span class="line">    return GA</span><br></pre></td></tr></table></figure>
<h3 id="Style-cost"><a href="#Style-cost" class="headerlink" title="Style cost"></a>Style cost</h3><p>生成了风格矩阵之后，你的目标就是最小化风格图片的Gram矩阵与生成图片的Gram矩阵的距离。这就可以写出一个损失函数，然后转化为一个最优化问题就行。</p>
<p><img src="/home/alex/图片/2018-167.png" alt="filename already ests, renamed"></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># GRADED FUNCTION: compute_layer_style_cost</span><br><span class="line"></span><br><span class="line">def compute_layer_style_cost(a_S, a_G):</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    Arguments:</span><br><span class="line">    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S </span><br><span class="line">    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G</span><br><span class="line">    </span><br><span class="line">    Returns: </span><br><span class="line">    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">    ### START CODE HERE ###</span><br><span class="line">    # Retrieve dimensions from a_G (≈1 line)</span><br><span class="line">    m, n_H, n_W, n_C = a_G.get_shape().as_list()</span><br><span class="line">    </span><br><span class="line">    new_shape = [n_H*n_W,n_C]</span><br><span class="line">    # Reshape the images to have them of shape (n_C, n_H*n_W) (≈2 lines)</span><br><span class="line">    a_S = tf.reshape(a_S,new_shape)</span><br><span class="line">    a_S = tf.transpose(a_S)</span><br><span class="line">    a_G = tf.reshape(a_G,new_shape)</span><br><span class="line">    a_G = tf.transpose(a_G)</span><br><span class="line">    # Computing gram_matrices for both images S and G (≈2 lines)</span><br><span class="line">    GS = gram_matrix(a_S)</span><br><span class="line">    GG = gram_matrix(a_G)</span><br><span class="line"></span><br><span class="line">    # Computing the loss (≈1 line)</span><br><span class="line">    J_style_layer = 1/(4*(n_H*n_W*n_C)**2)*tf.reduce_sum(tf.square(tf.subtract(GS,GG)))</span><br><span class="line">    </span><br><span class="line">    ### END CODE HERE ###</span><br><span class="line">    </span><br><span class="line">    return J_style_layer</span><br></pre></td></tr></table></figure>
<p>定义J_style</p>
<p><img src="/home/alex/图片/J_style.png" alt="upload suessful"></p>
<p>定义最终的cost</p>
<p><img src="/home/alex/图片/cosst.png" alt="upload ccessful"></p>
<p>再对这个损失函数求优化问题就行了。</p>
<p>result：<br><img src="/home/alex/图片/2018-168.png" alt="filenamlready exists, renamed"></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/31/DL-C4W3-YOLO/" rel="next" title="DL-C4W3(YOLO)">
                <i class="fa fa-chevron-left"></i> DL-C4W3(YOLO)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/01/03/DL-C5W1/" rel="prev" title="DL-C5W1">
                DL-C5W1 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/header.jpg"
                alt="Alex Chiu" />
            
              <p class="site-author-name" itemprop="name">Alex Chiu</p>
              <p class="site-description motion-element" itemprop="description">Alex's personal blog</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">52</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">categories</span>
                
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">4</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#人脸识别"><span class="nav-number">1.</span> <span class="nav-text">人脸识别</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#one-shot-learning"><span class="nav-number">1.1.</span> <span class="nav-text">one shot learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#siamese-network"><span class="nav-number">1.2.</span> <span class="nav-text">siamese network</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#三元组损失"><span class="nav-number">1.3.</span> <span class="nav-text">三元组损失</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#定义损失函数"><span class="nav-number">1.4.</span> <span class="nav-text">定义损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#挑选数据集"><span class="nav-number">1.5.</span> <span class="nav-text">挑选数据集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#summary"><span class="nav-number">1.6.</span> <span class="nav-text">summary</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#人脸验证与二分类"><span class="nav-number">2.</span> <span class="nav-text">人脸验证与二分类</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#预处理"><span class="nav-number">2.1.</span> <span class="nav-text">预处理</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#神经风格迁移"><span class="nav-number">3.</span> <span class="nav-text">神经风格迁移</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#梗概"><span class="nav-number">3.1.</span> <span class="nav-text">梗概</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#content-cost-function"><span class="nav-number">3.2.</span> <span class="nav-text">content cost function</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#style-cost-function"><span class="nav-number">4.</span> <span class="nav-text">style cost function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#implementation"><span class="nav-number">5.</span> <span class="nav-text">implementation</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#using-an-ConvNet-to-compute-encodings"><span class="nav-number">5.1.</span> <span class="nav-text">using an ConvNet to compute encodings</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#compute-triplet-loss"><span class="nav-number">5.2.</span> <span class="nav-text">compute triplet loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#verify"><span class="nav-number">5.3.</span> <span class="nav-text">verify</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#face-recognition"><span class="nav-number">6.</span> <span class="nav-text">face recognition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Neural-Style-Transfer"><span class="nav-number">7.</span> <span class="nav-text">Neural Style Transfer</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#compute-the-content-cost"><span class="nav-number">7.1.</span> <span class="nav-text">compute the content cost</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#STYLE-MATRIX"><span class="nav-number">7.2.</span> <span class="nav-text">STYLE MATRIX</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Style-cost"><span class="nav-number">8.</span> <span class="nav-text">Style cost</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Alex Chiu</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
